---
title: "Assignment 4"
author: "Mike Whitley"
date: "16/05/2021"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Assignment 4 Classification

A population of women who were at least 21 years old, of Pima Indian heritage and living near Phoenix,
Arizona, was tested for diabetes according toWorld Health Organization criteria. The data were collected
by the US National Institute of Diabetes and Digestive and Kidney Diseases.

```{r}
#install.packages("DAAG")
#install.packages("caret")
```


```{r}
pima_test <- read.table("pima_test.txt", sep = "" , header = T , nrows = 100,
                     na.strings ="", stringsAsFactors= F)
pima_train <- read.table("pima_train.txt", sep = "" , header = T , nrows = 100,
                     na.strings ="", stringsAsFactors= F)
head(pima_test)
head(pima_train)

```
1. Fit a Linear Discriminant Analysis model (function lda in package MASS) and calculate the misclassification
error on the provided test set. (2 marks)

for misclassification we want to use bayes classifier 

```{r}
library(MASS)
library(DAAG) #required for confusion matrix

```

```{r message=FALSE}

table(pima_train$type) #use this to work out 64 36 split for lda 1/k

attach(pima_train) 
lda_model <- lda(type ~ npreg + glu + bp + skin + bmi + ped + age, data=pima_train,         #completes LDA analysis
         prior=c(0.64, 0.36))  #0.36 and 0.64 is class proportion 
detach(pima_train)
lda_model
```

```{r, message=FALSE}
attach(pima_test)

#testing_predict <- predict(lda_model, data=pima_test) #Classify multivariate observations in conjunction with lda, and also project data onto the linear discriminants.


#table(Predicted=testing_predict$class, Type=type)      #this table should give me the data needed to calculate accuracy i.e error rate 
# The error rate is simply the number of misclassifications divided by the total sample size.so can check with using the table
#\\
#table(pima_train$type, testing_predict$class)

#library(caret)
#confusionMatrix(testing_predict$class, pima_test$type)

pred_value <- predict(lda_model, newdata=pima_test[,])$class
table(Type=pima_test$type, pred_value)

confusion(pima_test$type, pred_value) #81% accuracy so 19% misclassification 
#can check with 
#15 + 4 / 100 = 0.19 or 19%
detach(pima_test)
```

The misclassification error for LDA based on the training data is 0.19 or 19%


2. Which kind of misclassification is more common in the test data: patients with diabetes misclassified
as healthy, or healthy patients misclassified as having diabetes? (2 marks)

The category type equals 1 if diabetes is present and 0 otherwise.

Based on the table we can see that 4 people are false positive were they are predicted to have diabetes but don't have it whilst 15 people are false negative meaning they were predicted to not have diabetes however they do have it. Therefore more patients were misclassified as not having diabetes when they infact do have diabetes 


3. Fit a Quadratic discriminant Analysis model (function qda in package MASS). Write down the
misclassification error (Question 1) for the QDA model. (1 marks)

```{r message=FALSE}
attach(pima_train)
qda_model <- qda(type ~ npreg + glu + bp + skin + bmi + ped + age, data=pima_train,         #completes LDA analysis
         prior=c(0.64, 0.36))

pred_value_qda <- predict(qda_model, newdata=pima_test[,])$class
table(Type=pima_test$type, pred_value_qda)

confusion(pima_test$type, pred_value_qda) #0.27%

#confirm with 15+12 / 100 = 0.27
detach(pima_train)

```
The misclassification error of QDA model is 0.27 or 27% 


4. A health organisation wants you to recommend one of the two models for diagnosing diabetes. What
would you tell them? Explain your decision in a way that a non-statistician could understand. (2
marks)

Based on the amount of data we have here and the results I would recommend the Linear Discriminant Analysis model. We can see that when using the LDA model we have an accuracy rate of 81% meaning we correctly identify if the individual has diabetes, compared to the QDA model being only 73%. However as this is an health related issue of high important I would recommend gathering further data as Linear discriminant analysis preforms better with low observations and you may be able to further increase the predication percentage with more data to analyse. 


5. Fit a logistic regression model. What is the test error for this model? (1 mark)

```{r}
glm.fit=glm(type~npreg + glu + bp + skin + bmi + ped + age, data=pima_train, family=binomial)
summary(glm.fit)
```
```{r}
glm.probs=predict(glm.fit, newdata = pima_test, type="response")
glm.probs[1:10] #check the data for 10 entries

glm.pred=rep("No Diabeties",100)
glm.pred[glm.probs>.5]="Has Diabeties"
table(glm.pred, pima_test$type)

#checking the testing error
confusion(pima_test$type, glm.pred) #0.19%

#4+15 / 100 = 0.19 = 19% 
```
The test error for logistic regression is 19% or 0.19



